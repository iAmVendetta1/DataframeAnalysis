{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25dd2fd0-144a-4235-9f04-a14487d41b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                 # Importing the numpy library for numerical operations       \n",
    "import pandas as pd                # Importing the pandas library for data manipulation       \n",
    "import matplotlib.pyplot as plt    # Importing the matplotlib library for data visualization\n",
    "from sklearn.model_selection import train_test_split    # Importing the train_test_split function from scikit-learn for splitting data\n",
    "from sklearn.linear_model import LogisticRegression     # Importing the LogisticRegression model from scikit-learn\n",
    "from sklearn.preprocessing import StandardScaler        # Importing the StandardScaler for data normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e1f7c3-d5aa-438a-912f-f3009df0ac80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data from CSV files into pandas DataFrames\n",
    "case = pd.read_csv('example.csv', sep=',')\n",
    "time = pd.read_csv('example1.csv', sep=',')\n",
    "\n",
    "# Displaying the first few rows of the 'case' DataFrame\n",
    "case.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e7330e-076a-4dc0-9fd5-11ec8b35bdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping 'case' data by 'date', aggregating 'weekday', 'time', and 'status' columns, and resetting index\n",
    "date_grouped = case.groupby('date').agg({'weekday': 'first','time': 'sum','status': 'sum'}).reset_index()\n",
    "# Grouping 'time' data by 'date', aggregating 'weekday', 'time', and 'status' columns, and resetting index\n",
    "time_grouped = time.groupby('date').agg({'weekday': 'first','time': 'sum','status': 'sum'}).reset_index()\n",
    "\n",
    "# Concatenating the grouped 'case' and 'time' DataFrames\n",
    "case = pd.concat([date_grouped], ignore_index=True)\n",
    "time = pd.concat([time_grouped], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a64b52-f528-47fc-959e-e56cfea555d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the concatenated DataFrames to new CSV files\n",
    "new_file_path = 'case1.csv'\n",
    "case.to_csv(new_file_path, index=False)\n",
    "\n",
    "new_file_path1 = 'time1.csv'\n",
    "time.to_csv(new_file_path1, index=False)\n",
    "\n",
    "print(\"Data appended and saved to a new file successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b4c554-e699-46e6-b7f6-8fb272ff9b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the new CSV files into DataFrames\n",
    "case1 = pd.read_csv('case1.csv', sep=',')\n",
    "time1 = pd.read_csv('time1.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9394b8f9-324d-49ef-ae65-f0e18924634d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting 'date' column to datetime format\n",
    "case1['date'] = pd.to_datetime(case1['date'])\n",
    "\n",
    "# Extracting 'month', 'year', and 'day_of_week' from 'date' column\n",
    "case1['month'] = case1['date'].dt.month\n",
    "case1['year'] = case1['date'].dt.year\n",
    "case1['day_of_week'] = case1['date'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b755a25-b8b5-464d-a8a9-46e06605705a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting 'date' column to datetime format for 'time1' DataFrame\n",
    "time1['date'] = pd.to_datetime(time1['date'])\n",
    "\n",
    "# Extracting 'month', 'year', and 'day_of_week' from 'date' column for 'time1' DataFrame\n",
    "time1['month'] = time1['date'].dt.month\n",
    "time1['year'] = time1['date'].dt.year\n",
    "time1['day_of_week'] = time1['date'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b21dab-1543-40e2-bc01-cebeadc9371d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping 'case1' data by 'year', aggregating 'time' and 'status', and resetting index\n",
    "casetime = case1.groupby('year', as_index=False).agg({'year': 'first','time': 'sum','status': 'sum'})\n",
    "\n",
    "# Grouping 'time1' data by 'year', aggregating 'time' and 'status', and resetting index\n",
    "totaltime = time1.groupby('year', as_index=False).agg({'year': 'first','time': 'sum','status': 'sum'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50501e4f-fb9d-4411-9458-3a8b4dfe1465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the dataframes on 'date'\n",
    "merged_df = pd.merge(case1, time1, on='date', suffixes=('_case', '_time'), how='outer')\n",
    "\n",
    "# Use np.where to conditionally select 'techtime' and 'status'\n",
    "merged_df['time'] = np.where(merged_df['time_time'].notna(), merged_df['time_time'], merged_df['time_cases'])\n",
    "merged_df['status'] = merged_df['status_cases']\n",
    "\n",
    "# Select the 'weekday', 'year', and 'month' columns from one of the original dataframes\n",
    "merged_df['weekday'] = merged_df['weekday_cases'].combine_first(merged_df['weekday_time'])\n",
    "merged_df['year'] = merged_df['year_cases'].combine_first(merged_df['year_time'])\n",
    "merged_df['month'] = merged_df['month_cases'].combine_first(merged_df['month_time'])\n",
    "\n",
    "# Drop the extra columns\n",
    "merged_df = merged_df[['date', 'year', 'month', 'weekday', 'time', 'status']]\n",
    "\n",
    "# Display the result\n",
    "merged_df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfd47c0-00d1-4401-a05c-29554b731257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'year' and 'weekday', calculate mean of 'time' and 'status'\n",
    "daily = merged_df.groupby(['year', 'weekday'], as_index=False).agg({'time': 'mean','status': 'mean'})\n",
    "daily.head(30)\n",
    "\n",
    "# Group by 'year', aggregate 'time' and 'status', and reset index\n",
    "mergedtime = merged_df.groupby('year', as_index=False).agg({'year': 'first','time': 'sum','status': 'sum'})\n",
    "mergedtime.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d9b523-4ffb-4693-a693-28a1d10d2e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import seaborn for data visualization and configure settings\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set inline plotting for Jupyter Notebooks\n",
    "%matplotlib inline\n",
    "\n",
    "# Pairplot to visualize relationships between variables, color-coded by 'weekday'\n",
    "sns.pairplot(merged_df, hue=\"weekday\")\n",
    "plt.show()    #Displays the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ba056a-4b5f-4402-bbce-2a3324a32cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create subplots with 1 row and 2 columns for bar plots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Bar plot for 'time' by 'year', with bars colored by 'year'\n",
    "sns.barplot(data=merged_df, x='year', y='time', hue='year', ax=axes[0])\n",
    "axes[0].set_title('Average Daily Time by Year')   # Set title for the first subplot\n",
    "axes[0].set_ylim(0, 10)  # Set y-axis limit for the first subplot\n",
    "axes[0].legend(loc='upper right', bbox_to_anchor=(0.9, 0.925))   # Adjust legend position\n",
    "\n",
    "# Bar plot for 'status' by 'year', with bars colored by 'year'\n",
    "sns.barplot(data=merged_df, x='year', y='status', hue='year', ax=axes[1])\n",
    "axes[1].set_title('Average Daily Closes by Year')  # Set title for the second subplot\n",
    "axes[1].set_ylim(0, 15)  # Set y-axis limit for the second subplot\n",
    "axes[1].legend(loc='upper right', bbox_to_anchor=(0.9, 0.925))  # Adjust legend position\n",
    "\n",
    "# Adjust layout to prevent overlapping\n",
    "plt.tight_layout()\n",
    "plt.show()   # Display the plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc008081-554f-4ae7-a4bd-1b77430cc826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same instance as above but for mergedtime instead of merged_df\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "sns.barplot(data=mergedtime, x='year', y='time', hue='year', ax=axes[0])\n",
    "axes[0].set_title('Time by Year')\n",
    "axes[0].set_ylim(0, 1250)\n",
    "axes[0].legend(loc='upper right', bbox_to_anchor=(0.9, 0.925))\n",
    "\n",
    "sns.barplot(data=mergedtime, x='year', y='status', hue='year', ax=axes[1])\n",
    "axes[1].set_title('Closes by Year')\n",
    "axes[1].set_ylim(0, 2500)\n",
    "axes[1].legend(loc='upper right', bbox_to_anchor=(0.9, 0.925))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
